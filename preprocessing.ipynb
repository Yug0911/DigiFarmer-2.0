{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import joblib\n",
    "import streamlit as st\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('merged_dataset.csv')\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values (if any)\n",
    "# For numerical columns, fill with mean\n",
    "numerical_cols = ['n', 'p', 'k', 'temperature', 'humidity', 'ph', 'rainfall', 'moisture', 'windspeed']\n",
    "for col in numerical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# For categorical columns, fill with mode\n",
    "categorical_cols = ['soil_type', 'crop']\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Encode Soil Type\n",
    "le = LabelEncoder()\n",
    "df['soil_type_encoded'] = le.fit_transform(df['soil_type'])\n",
    "\n",
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "# Features and target\n",
    "X = df[numerical_cols + ['soil_type_encoded']]\n",
    "y = df['crop']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save preprocessor\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(le, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "# Distribution plots\n",
    "for col in numerical_cols + ['soil_type_encoded']:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(df[numerical_cols + ['soil_type_encoded']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Comparison of features by crop\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='crop', y=col, data=df)\n",
    "    plt.title(f'{col} by Crop')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and Train Models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "    print(f'{name} trained.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models\n",
    "results = {}\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'Confusion Matrix': cm\n",
    "    }\n",
    "    \n",
    "    print(f'{name} Results:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-Score: {f1:.4f}')\n",
    "    print(f'Confusion Matrix:\\n{cm}')\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Best Model\n",
    "best_model_name = max(results, key=lambda x: results[x]['F1-Score'])\n",
    "best_model = trained_models[best_model_name]\n",
    "print(f'Best Model: {best_model_name} with F1-Score: {results[best_model_name][\"F1-Score\"]:.4f}')\n",
    "\n",
    "# Save best model\n",
    "joblib.dump(best_model, 'best_crop_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Function\n",
    "def predict_crop(n, p, k, temperature, humidity, ph, rainfall, moisture, soil_type, windspeed):\n",
    "    # Load preprocessors\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    le = joblib.load('label_encoder.pkl')\n",
    "    model = joblib.load('best_crop_model.pkl')\n",
    "    \n",
    "    # Prepare input\n",
    "    input_data = pd.DataFrame({\n",
    "        'n': [n], 'p': [p], 'k': [k], 'temperature': [temperature],\n",
    "        'humidity': [humidity], 'ph': [ph], 'rainfall': [rainfall],\n",
    "        'moisture': [moisture], 'windspeed': [windspeed]\n",
    "    })\n",
    "    \n",
    "    # Scale numerical features\n",
    "    input_data[numerical_cols] = scaler.transform(input_data[numerical_cols])\n",
    "    \n",
    "    # Encode soil type\n",
    "    soil_encoded = le.transform([soil_type])[0]\n",
    "    input_data['soil_type_encoded'] = soil_encoded\n",
    "    \n",
    "    # Predict\n",
    "    prediction = model.predict(input_data)\n",
    "    \n",
    "    return prediction[0]\n",
    "\n",
    "# Test the function\n",
    "print(predict_crop(90, 42, 43, 20.87, 82.00, 6.50, 202.93, 29.44, 2, 10.10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
